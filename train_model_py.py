# -*- coding: utf-8 -*-
"""train_model.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aqx94RQ7dlHuEDgxoUVH5ZdfKNB6oeUU
"""

!pip install openpyxl

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load data
df = pd.read_excel("simulated_mine_water_treatment_data.xlsx")

# Define variables
input_vars = [
    'pH_raw', 'Turbidity_raw_NTU', 'Temperature_C', 'Fe_initial_mg_L', 'Mn_initial_mg_L', 'Cu_initial_mg_L',
    'Zn_initial_mg_L', 'Suspended_solids_mg_L', 'TDS_mg_L'
]
output_vars = [
    'Turbidity_final_NTU', 'Fe_final_mg_L', 'Mn_final_mg_L', 'Cu_final_mg_L',
    'Zn_final_mg_L', 'Suspended_solids_final_mg_L', 'TDS_final_mg_L',
    'Turbidity_removal_%', 'Suspended_solids_removal_%', 'TDS_removal_%', 'Coagulant_dose_mg_L',
    'Flocculant_dose_mg_L', 'Mixing_speed_rpm',
    'Rapid_mix_time_min', 'Slow_mix_time_min', 'Settling_time_min'
]

X = df[input_vars].values
y = df[output_vars].values

# Normalize
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

# Define model
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(64, activation='relu'),
    Dense(y_train.shape[1], activation='linear')
])
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train model
history = model.fit(X_train, y_train, validation_split=0.1, epochs=150, batch_size=16, verbose=1)

# Predict
y_pred_scaled = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test_orig = scaler_y.inverse_transform(y_test)

# Evaluate
mae = mean_absolute_error(y_test_orig, y_pred)
rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))
r2 = r2_score(y_test_orig, y_pred)

print("Model Evaluation:")
print(f"MAE:  {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²:   {r2:.4f}")

import matplotlib.pyplot as plt

# Plot predicted vs actual for each output variable
def plot_real_vs_predicted(y_true, y_pred, var_names, title_prefix=""):
    n_outputs = y_true.shape[1]
    plt.figure(figsize=(20, 25))
    for i in range(n_outputs):
        plt.subplot(6, 3, i + 1)
        plt.scatter(y_true[:, i], y_pred[:, i], alpha=0.6, edgecolors='k')
        plt.plot([y_true[:, i].min(), y_true[:, i].max()],
                 [y_true[:, i].min(), y_true[:, i].max()],
                 'r--', lw=2)
        plt.xlabel("Actual")
        plt.ylabel("Predicted")
        plt.title(f"{title_prefix}{var_names[i]}")
        plt.grid(True)
    plt.tight_layout()
    plt.show()

# Run the plot
plot_real_vs_predicted(y_test_orig, y_pred, output_vars, title_prefix="Predicted vs Actual: ")

import numpy as np

# Example: define a new test input (must match order of input_vars)
# You can replace these values with any realistic test case
new_input = np.array([
    [7.5,   # pH_raw
     45.0,  # Turbidity_raw_NTU
     25.0,  # Temperature_C
     1.2,   # Fe_initial_mg_L
     0.3,   # Mn_initial_mg_L
     0.05,  # Cu_initial_mg_L
     0.1,   # Zn_initial_mg_L
     150.0, # Suspended_solids_mg_L
     1000.0]# TDS_mg_L

])

# Scale using training scaler
new_input_scaled = scaler_X.transform(new_input)

# Predict using the trained model
predicted_output_scaled = model.predict(new_input_scaled)

# Inverse transform to get real-world output values
predicted_output = scaler_y.inverse_transform(predicted_output_scaled)

# Show first 7 predicted results
print("\nPredicted Treated Water Quality:")
for i, var in enumerate(output_vars[:10]):
    print(f"{var}: {predicted_output[0, i]:.3f}")

# Show remaining predicted results
print("\nOperation Process Parameters:")
for i, var in enumerate(output_vars[10:], start=7):
    print(f"{var}: {predicted_output[0, i]:.3f}")

# Define limits for safe reuse
limits = {
    'Turbidity_final_NTU': (0.0, 5.0),
    'Fe_final_mg_L': (0.0, 0.3),
    'Mn_final_mg_L': (0.0, 0.1),
    'Cu_final_mg_L': (0.0, 1.0),
    'Zn_final_mg_L': (0.0, 5.0),
    'Suspended_solids_final_mg_L': (0.0, 50.0),
    'TDS_final_mg_L': (0.0, 1000.0)
}

# Check if all values are within limits
status_messages = []

for i, var in enumerate(output_vars[:7]):  # First 7 are final quality values
    min_val, max_val = limits.get(var, (None, None))
    value = predicted_output[0, i]  # Use the correct index from i
    if min_val is not None and min_val <= value <= max_val:
        status_messages.append(f"{var}: ✅ Within limit")
    else:
        status_messages.append(f"{var}: ❌ Out of limit")

print("\nWater Reuse Assessment:")
for msg in status_messages:
    print(msg)

if reuse_safe:
    print("\n✅ Result: Water is safe for reuse or discharge.")
else:
    print("\n❌ Result: Water is NOT safe for reuse or discharge.")

pip install streamlit numpy pandas scikit-learn tensorflow

pip install streamlit

pip install streamlit numpy pandas scikit-learn tensorflow joblib

import numpy as np
import pandas as pd
import joblib
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split

# Define your experimental data (replace this with real data)
data = {
    'pH_raw': np.random.uniform(3.0, 11.0, 200),
    'turbidity_raw': np.random.uniform(0.1, 500.0, 200),
    'temperature': np.random.uniform(5.0, 40.0, 200),
    'coagulant_dose': np.random.uniform(0.0, 100.0, 200),
    'flocculant_dose': np.random.uniform(0.0, 20.0, 200),
    'fe_initial': np.random.uniform(0.0, 10.0, 200),
    'mn_initial': np.random.uniform(0.0, 5.0, 200),
    'cu_initial': np.random.uniform(0.0, 2.0, 200),
    'zn_initial': np.random.uniform(0.0, 5.0, 200),
    'ss': np.random.uniform(0.0, 1000.0, 200),
    'tds': np.random.uniform(0.0, 5000.0, 200),
    'mixing_speed': np.random.uniform(50, 500, 200),
    'rapid_mix': np.random.uniform(0.5, 10.0, 200),
    'slow_mix': np.random.uniform(1.0, 30.0, 200),
    'settling_time': np.random.uniform(5.0, 60.0, 200),
    'Turbidity_final_NTU': np.random.uniform(0, 5, 200),
    'Fe_final_mg_L': np.random.uniform(0, 0.3, 200),
    'Mn_final_mg_L': np.random.uniform(0, 0.1, 200),
    'Cu_final_mg_L': np.random.uniform(0, 1.0, 200),
    'Zn_final_mg_L': np.random.uniform(0, 5.0, 200),
    'Suspended_solids_final_mg_L': np.random.uniform(0, 50.0, 200),
    'TDS_final_mg_L': np.random.uniform(0, 1000.0, 200),
    'Turbidity_removal_%': np.random.uniform(50, 95, 200),
    'Suspended_solids_removal_%': np.random.uniform(50, 95, 200),
    'TDS_removal_%': np.random.uniform(50, 95, 200),
}

# Convert to DataFrame
df = pd.DataFrame(data)

# Separate independent (features) and dependent (target) variables
X = df.drop(columns=['Turbidity_final_NTU', 'Fe_final_mg_L', 'Mn_final_mg_L', 'Cu_final_mg_L', 'Zn_final_mg_L',
                     'Suspended_solids_final_mg_L', 'TDS_final_mg_L', 'Turbidity_removal_%',
                     'Suspended_solids_removal_%','TDS_removal_%','coagulant_dose','flocculant_dose', 'mixing_speed',
    'rapid_mix', 'slow_mix', 'settling_time'])

y = df[['Turbidity_final_NTU', 'Fe_final_mg_L', 'Mn_final_mg_L', 'Cu_final_mg_L', 'Zn_final_mg_L',
        'Suspended_solids_final_mg_L', 'TDS_final_mg_L', 'Turbidity_removal_%',
        'Suspended_solids_removal_%', 'TDS_removal_%','coagulant_dose','flocculant_dose', 'mixing_speed',
    'rapid_mix', 'slow_mix', 'settling_time']]

# Split data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data using StandardScaler
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# Build the ANN model
model = Sequential()
model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y_train_scaled.shape[1], activation='linear'))  # Output layer for multiple regression

model.compile(loss='mean_squared_error', optimizer='adam')

# Train the model
model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_scaled))

# Save the model and scalers
model.save('ann_water_model.h5')
joblib.dump(scaler_X, 'scaler_X.pkl')
joblib.dump(scaler_y, 'scaler_y.pkl')

print("Model training complete and files saved as 'ann_water_model.h5', 'scaler_X.pkl', 'scaler_y.pkl'.")

import streamlit as st
from PIL import Image
import numpy as np
import pandas as pd
import joblib
from tensorflow.keras.models import load_model
import base64

# --- Display Logo ---
logo = Image.open("ttu_logo.png")
st.image(logo, width=900)

# --- Header Info ---
st.markdown("""
<h2 style='text-align: center; color: navy;'>Graduation Project II</h2>
<h3 style='text-align: center; color: darkgreen;'>College of Engineering / Natural Resources and Chemical Engineering Department</h3>
<h4 style='text-align: center;'>Tafila Technical University</h4>
<h5 style='text-align: center; color: gray;'>Designed and implemented by students:</h5>
<ul style='text-align: center; list-style: none; padding-left: 0;'>
    <li>1 - Duaa</li>
    <li>2 - Shahed</li>
    <li>3 - Rahaf</li>
</ul>
""", unsafe_allow_html=True)

# --- Load ML Model and Scalers ---
scaler_X = joblib.load('scaler_X.pkl')
scaler_y = joblib.load('scaler_y.pkl')
model = load_model('ann_water_model.h5')

output_vars = [
    'Turbidity_final_NTU', 'Fe_final_mg_L', 'Mn_final_mg_L', 'Cu_final_mg_L',
    'Zn_final_mg_L', 'Suspended_solids_final_mg_L', 'TDS_final_mg_L',
    'Turbidity_removal_%', 'Suspended_solids_removal_%', 'TDS_removal_%','Coagulant_dose_mg_L',
    'Flocculant_dose_mg_L', 'Mixing_speed_rpm',
    'Rapid_mix_time_min', 'Slow_mix_time_min', 'Settling_time_min'
]

limits = {
    'Turbidity_final_NTU': (0.0, 5.0),
    'Fe_final_mg_L': (0.0, 0.3),
    'Mn_final_mg_L': (0.0, 0.1),
    'Cu_final_mg_L': (0.0, 1.0),
    'Zn_final_mg_L': (0.0, 5.0),
    'Suspended_solids_final_mg_L': (0.0, 50.0),
    'TDS_final_mg_L': (0.0, 1000.0)
}

# --- Title & Form ---
st.title("Water Treatment Quality Predictor (ANN-based)")
st.markdown("Enter experimental values below to predict treated water quality and assess reuse suitability.")

with st.form("input_form"):
    pH_raw = st.slider("pH of Raw Water", 3.0, 11.0, 7.0)
    turbidity_raw = st.slider("Turbidity (NTU)", 0.1, 500.0, 50.0)
    temperature = st.slider("Temperature (°C)", 5.0, 40.0, 25.0)
    fe_initial = st.slider("Initial Fe (mg/L)", 0.0, 10.0, 1.0)
    mn_initial = st.slider("Initial Mn (mg/L)", 0.0, 5.0, 0.3)
    cu_initial = st.slider("Initial Cu (mg/L)", 0.0, 2.0, 0.05)
    zn_initial = st.slider("Initial Zn (mg/L)", 0.0, 5.0, 0.1)
    ss = st.slider("Suspended Solids (mg/L)", 0.0, 1000.0, 150.0)
    tds = st.slider("TDS (mg/L)", 0.0, 5000.0, 1000.0)

    submitted = st.form_submit_button("Test Water Quality")

# --- Prediction Logic ---
if submitted:
    input_array = np.array([[pH_raw, turbidity_raw, temperature, coagulant_dose, flocculant_dose,
                             fe_initial, mn_initial, cu_initial, zn_initial, ss, tds,
                             mixing_speed, rapid_mix, slow_mix, settling_time]])

    X_scaled = scaler_X.transform(input_array)
    y_pred_scaled = model.predict(X_scaled)
    y_pred = scaler_y.inverse_transform(y_pred_scaled)[0]

    # --- Build Result Table ---
    results = pd.DataFrame(columns=["Parameter", "Predicted Value", "Standard Limit", "Unit", "Assessment"])

    units = ['NTU', 'mg/L', 'mg/L', 'mg/L', 'mg/L', 'mg/L', 'mg/L', '%', '%', '%']
    reuse_safe = True

    for i, var in enumerate(output_vars):
        value = y_pred[i]
        if var in limits:
            std_text, limit_val = limits[var]
            assessment = "✅ OK" if value <= limit_val else "❌ Exceeds Limit"
            if value > limit_val:
                reuse_safe = False
        else:
            std_text = "--"
            assessment = "--"

        results.loc[i] = [var, round(value, 3), std_text, units[i], assessment]

    # --- Display Table ---
    st.subheader("Predicted Treated Water Quality")
    st.dataframe(results)

    # --- Decision Message ---
    st.subheader("Reuse Decision")
    if reuse_safe:
        st.success("✅ Water is safe for reuse or discharge.")
    else:
        st.error("❌ Water does NOT meet quality standards for reuse.")

    # --- PDF Report Generation ---
    def create_pdf(df, reuse_safe):
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        pdf.cell(200, 10, "Water Quality Prediction Report", ln=True, align='C')

        pdf.ln(10)
        for index, row in df.iterrows():
            pdf.cell(200, 10, f"{row['Parameter']}: {row['Predicted Value']} {row['Unit']} (Standard: {row['Standard Limit']}) --> {row['Assessment']}", ln=True)

        pdf.ln(10)
        decision = "Water is safe for reuse or discharge." if reuse_safe else "Water does NOT meet reuse standards."
        pdf.multi_cell(0, 10, f"Final Decision:\n{decision}")

        return pdf

    # Generate and download PDF
    pdf = create_pdf(results, reuse_safe)
    pdf.output("report.pdf")

    with open("report.pdf", "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode("utf-8")

    href = f'<a href="data:application/pdf;base64,{base64_pdf}" download="water_quality_report.pdf">📥 Download Report as PDF</a>'
    st.markdown(href, unsafe_allow_html=True)